<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mohamed Hassan</title>
  
  <meta name="author" content="Mohamed Hassan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:63%;vertical-align:middle">
                            <p style="text-align:center">
                                <name>Mohamed Hassan</name>
                            </p>
                            <p>
                                I am a Ph.D. student at <a href="https://ps.is.tuebingen.mpg.de/employees/mhassan">Max Planck Institute for Intelligent Systems</a>,
                                where I work on computer vision and computer graphics and machine learning. I am advised by <a href="https://ps.is.tuebingen.mpg.de/person/black"> Michael Black</a>.
                                I am interested in reconstructing, analyzing, and generating Human-Scene Interaction.
                            </p>

                            <p>
                                I had a lot of fun doing an internship at Adobe in the summer of 2020. I worked with <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                                <a href="https://rubenvillegas.github.io/">Ruben Villegas</a>, <a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>,
                                <a href="https://zhouyisjtu.github.io/">Yi Zhou</a>, and <a href="https://eng.ucmerced.edu/people/jyang44">Jimei Yang</a>.
                            </p>

                            <p style="text-align:center">
                                <a href="mailto:mohamed.hassan@tuebingen.mpg.de">Email</a> &nbsp/&nbsp
                                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                                <a href="https://scholar.google.com/citations?user=qWfJbHMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                                <a href="https://twitter.com/M_E_Hassan">Twitter</a> &nbsp/&nbsp
                                <a href="https://github.com/mohamedhassanmus">Github</a>
                            </p>
                        </td>
                        <td style="padding:2.5%;width:40%;max-width:40%">
                            <a href="images/profile_pic.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic.png" class="hoverZoomLink"></a>
                        </td>
                    </tr>
                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/POSA.png" alt="POSA" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://posa.is.tue.mpg.de">
                                <papertitle>Populating 3D Scenes by Learning Human-Scene Interaction</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/pghosh">Partha Ghosh</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/jtesch">Joachim Tesch</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/dtzionas">Dimitrios Tzionas</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                            <br>
                            <em>arXiv</em>, 2020
                            <br>
                            <p> Automatically place 3D scans of people in scenes.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/PSI.png" alt="PSI" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://ps.is.tuebingen.mpg.de/publications/smpl-x-conditional-vae-prox-scene-constraints">
                                <papertitle>Generating 3D People in Scenes without People</papertitle>
                            </a>
                            <br>
                            <a href="https://ps.is.tuebingen.mpg.de/employees/yzhang">Yan Zhang</a>,
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>,
                            <a href="https://vlg.inf.ethz.ch/people/person-detail.siyutang.html">Siyu Tang</a>

                            <br>
                            <em>CVPR</em>, 2019
                            <br>
                            <p> Generates 3D human bodies in 3D scenes.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/PROX.png" alt="PROX" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://prox.is.tue.mpg.de/">
                                <papertitle>Resolving 3D Human Pose Ambiguities with 3D Scene Constraints</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://vchoutas.github.io/">Vasileios Choutas</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/dtzionas">Dimitrios Tzionas</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                            <br>
                            <em>ICCV</em>, 2019
                            <br>
                            <p> Exploit static 3D scene structure to better estimate human pose from monocular images. Introduce the PROX dataset.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/MultipleSign.png" alt="Multiple proposals ArSLR" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://link.springer.com/content/pdf/10.1007/s11220-019-0225-3.pdf">
                                <papertitle>Multiple proposals for continuous arabic sign language recognition</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://scholar.google.com/citations?user=nq7m6zcAAAAJ&hl=en">Khaled Assaleh</a>,
                            <a href="https://scholar.google.com/citations?user=Bm2wldYAAAAJ&hl=en">Tamer Shanableh</a>
                            <br>
                            <em>Sensing and Imaging</em>, 2019
                            <br>
                            <p> Comparison between two diferent recognition techniques for continuous Arabic Sign Language Recognition (ArSLR) for multiple users.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/UserSign.png" alt="User-dependent ArSLR" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881458">
                                <papertitle> User-dependent Sign Language Recognition Using Motion Detection </papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://scholar.google.com/citations?user=nq7m6zcAAAAJ&hl=en">Khaled Assaleh</a>,
                            <a href="https://scholar.google.com/citations?user=Bm2wldYAAAAJ&hl=en">Tamer Shanableh</a>
                            <br>
                            <em>International Conference on Computational Science and Computational Intelligence</em>, 2016
                            <br>
                            <p> Continuous sensor-based Arabic Sign Language Recognition (ArSLR) system based on Hidden Markov Models(HMM) and a modified version of k-nearest neighbor(KNN).
                            </p>
                        </td>
                    </tr>



                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr>
                        <td style="padding:0px">
                            <br>
                            <p style="text-align:right;font-size:small;">
                                <a href="http://jonbarron.info/">Cool website template</a> 
                </tbody>
            </table>

        </td>
    </tr>
</table>
</body>

</html>
