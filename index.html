<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mohamed Hassan</title>
  
  <meta name="author" content="Mohamed Hassan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:63%;vertical-align:middle">
                            <p style="text-align:center">
                                <name>Mohamed Hassan</name>
                            </p>
                            <p>
                                is an AI Scientist at Electronic Arts working on learning-based character animation. I hold a Ph.D. from <a href="https://ps.is.tuebingen.mpg.de/employees/mhassan">Max Planck Institute for Intelligent Systems</a>,
                                where I worked on computer vision, computer graphics and machine learning. I was advised by <a href="https://ps.is.tuebingen.mpg.de/person/black"> Michael Black</a>.
                                In my PhD thesis, I explored the reconstruction, analysis, and generation of Human-Scene Interaction.
                            </p>

                            <p>
                                During my Ph.D., I was an intern at <a href="https://nv-tlabs.github.io/">Nvidia Toronto AI lab</a> where I worked with <a href="https://www.cs.utoronto.ca/~fidler">Sanja Filder</a> and <a href="https://xbpeng.github.io/">Jason Peng</a>.
                                I had a lot of fun doing an internship at Adobe Research in the summer of 2020. I worked with <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                                <a href="https://rubenvillegas.github.io/">Ruben Villegas</a>, <a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>,
                                <a href="https://zhouyisjtu.github.io/">Yi Zhou</a>, and <a href="https://eng.ucmerced.edu/people/jyang44">Jimei Yang</a>.
                            </p>

                            <p>
                                In my free time, I like to mentor undergraduate students from my alma mater in Sudan. I enjoy reading about history, philosophy, and economics.
                                I also like to cycle, run, and train in martial arts.
                            </p>

                            <p style="text-align:center">
                                <a href="mailto:mohamed.hassan.mus@gmail.com">Email</a> &nbsp/&nbsp
                                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                                <a href="https://scholar.google.com/citations?user=qWfJbHMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                                <a href="https://twitter.com/M_E_Hassan">Twitter</a> &nbsp/&nbsp
                                <a href="https://github.com/mohamedhassanmus">Github</a>
                            </p>
                        </td>
                        <td style="padding:2.5%;width:40%;max-width:40%">
                            <a href="images/profile_pic_2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic_2.jpg" class="hoverZoomLink"></a>
                        </td>
                    </tr>
                </tbody>
            </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                  <li> <strong>September 2022</strong>: I joined Electronic Arts as an AI scientist working on character animation. </a>.</li>
                  <li> <strong>June 2021</strong>: I gave a talk about computer vision applications at the <a href="https://youtu.be/zYObAWGTg2o">Sudanse Machine Learning Community</a>.</li>
                  <li> <strong>June 2021</strong>:  I joined <a href="https://nv-tlabs.github.io/">Nvidia Toronto AI lab</a> led by <a href="https://www.cs.utoronto.ca/~fidler">Sanja Filder</a> for an internship.</li>
              </ul>
         
            </td>
          </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/interphys.png" alt="InterPhys" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://xbpeng.github.io/projects/InterPhys/index.html">
                                <papertitle>Synthesizing Physical Character-Scene Interactions</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="">Yunrong Guo</a>,
                            <a href="">Tingwu Wang</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                            <a href="https://www.cs.utoronto.ca/~fidler">Sanja Fidler</a>,
                            <a href="https://xbpeng.github.io/>Xue Bin Peng</a>,
                            <br>
                            <em>SIGGRAPH </em>, 2023
                            <br>
                            <p> Generating physical and realistic human-scene interactions without manual labeling. Generalize beyond the objects and scenarios depicted in the training dataset.</p>
                        </td>
                    </tr>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/SAMP_2.png" alt="SAMP" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://samp.is.tue.mpg.de">
                                <papertitle>Stochastic Scene-Aware Motion Prediction</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                            <a href="">Ruben Villegas</a>,
                            <a href="">Jun Saito</a>,
                            <a href="">Jimei Yang</a>,
                            <a href="">Yi Zhou</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                            <br>
                            <em>ICCV</em>, 2021
                            <br>
                            <p> Generating realistic and diverse styles of human-scene interactions.</p>
                        </td>
                    </tr>
<!---->


                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/POSA.png" alt="POSA" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://posa.is.tue.mpg.de">
                                <papertitle>Populating 3D Scenes by Learning Human-Scene Interaction</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/pghosh">Partha Ghosh</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/jtesch">Joachim Tesch</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/dtzionas">Dimitrios Tzionas</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                            <br>
                            <em>CVPR</em>, 2021
                            <br>
                            <p> Automatically place 3D scans of people in scenes.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/PSI.png" alt="PSI" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://ps.is.tuebingen.mpg.de/publications/smpl-x-conditional-vae-prox-scene-constraints">
                                <papertitle>Generating 3D People in Scenes without People</papertitle>
                            </a>
                            <br>
                            <a href="https://ps.is.tuebingen.mpg.de/employees/yzhang">Yan Zhang</a>,
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>,
                            <a href="https://vlg.inf.ethz.ch/people/person-detail.siyutang.html">Siyu Tang</a>

                            <br>
                            <em>CVPR</em>, 2019
                            <br>
                            <p> Generates 3D human bodies in 3D scenes.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/PROX.png" alt="PROX" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://prox.is.tue.mpg.de/">
                                <papertitle>Resolving 3D Human Pose Ambiguities with 3D Scene Constraints</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://vchoutas.github.io/">Vasileios Choutas</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/dtzionas">Dimitrios Tzionas</a>,
                            <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                            <br>
                            <em>ICCV</em>, 2019
                            <br>
                            <p> Exploit static 3D scene structure to better estimate human pose from monocular images. Introduce the PROX dataset.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/MultipleSign.png" alt="Multiple proposals ArSLR" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://link.springer.com/content/pdf/10.1007/s11220-019-0225-3.pdf">
                                <papertitle>Multiple proposals for continuous arabic sign language recognition</papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://scholar.google.com/citations?user=nq7m6zcAAAAJ&hl=en">Khaled Assaleh</a>,
                            <a href="https://scholar.google.com/citations?user=Bm2wldYAAAAJ&hl=en">Tamer Shanableh</a>
                            <br>
                            <em>Sensing and Imaging</em>, 2019
                            <br>
                            <p> Comparison between two diferent recognition techniques for continuous Arabic Sign Language Recognition (ArSLR) for multiple users.</p>
                        </td>
                    </tr>
<!---->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/UserSign.png" alt="User-dependent ArSLR" style="border-style: none">
                        </td>
                        <td width="75%" valign="middle">
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881458">
                                <papertitle> User-dependent Sign Language Recognition Using Motion Detection </papertitle>
                            </a>
                            <br>
                            <strong>Mohamed Hassan</strong>,
                            <a href="https://scholar.google.com/citations?user=nq7m6zcAAAAJ&hl=en">Khaled Assaleh</a>,
                            <a href="https://scholar.google.com/citations?user=Bm2wldYAAAAJ&hl=en">Tamer Shanableh</a>
                            <br>
                            <em>International Conference on Computational Science and Computational Intelligence</em>, 2016
                            <br>
                            <p> Continuous sensor-based Arabic Sign Language Recognition (ArSLR) system based on Hidden Markov Models(HMM) and a modified version of k-nearest neighbor(KNN).
                            </p>
                        </td>
                    </tr>



                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr>
                        <td style="padding:0px">
                            <br>
                            <p style="text-align:right;font-size:small;">
                                <a href="http://jonbarron.info/">Cool website template</a> 
                </tbody>
            </table>

        </td>
    </tr>
</table>
</body>

</html>
